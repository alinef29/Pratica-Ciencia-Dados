{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a4fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\aline\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ucimlrepo) (2.2.2)\n",
      "Collecting certifi>=2020.12.5 (from ucimlrepo)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aline\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aline\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aline\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aline\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aline\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: certifi, ucimlrepo\n",
      "Successfully installed certifi-2025.4.26 ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0a2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\aline\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aline\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 1.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/11.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.1/11.1 MB 1.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.6/11.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.4/11.1 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.7/11.1 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.2/11.1 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.2/11.1 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.5/11.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.8/11.1 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.8/11.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.1/11.1 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.6/11.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.7/11.1 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.1 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.2/11.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14c4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Carregar os dados\n",
    "#dados = pd.read_csv('seu_arquivo.csv', parse_dates=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8238f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 27, 'name': 'Credit Approval', 'repository_url': 'https://archive.ics.uci.edu/dataset/27/credit+approval', 'data_url': 'https://archive.ics.uci.edu/static/public/27/data.csv', 'abstract': 'This data concerns credit card applications; good mix of attributes', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 690, 'num_features': 15, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['A16'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1987, 'last_updated': 'Wed Aug 23 2023', 'dataset_doi': '10.24432/C5FS30', 'creators': ['J. R. Quinlan'], 'intro_paper': None, 'additional_info': {'summary': 'This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.\\r\\n  \\r\\nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'A1:\\tb, a.\\r\\nA2:\\tcontinuous.\\r\\nA3:\\tcontinuous.\\r\\nA4:\\tu, y, l, t.\\r\\nA5:\\tg, p, gg.\\r\\nA6:\\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\\r\\nA7:\\tv, h, bb, j, n, z, dd, ff, o.\\r\\nA8:\\tcontinuous.\\r\\nA9:\\tt, f.\\r\\nA10:\\tt, f.\\r\\nA11:\\tcontinuous.\\r\\nA12:\\tt, f.\\r\\nA13:\\tg, p, s.\\r\\nA14:\\tcontinuous.\\r\\nA15:\\tcontinuous.\\r\\nA16: +,-         (class attribute)', 'citation': None}}\n",
      "   name     role         type demographic description units missing_values\n",
      "0   A16   Target  Categorical        None        None  None             no\n",
      "1   A15  Feature   Continuous        None        None  None             no\n",
      "2   A14  Feature   Continuous        None        None  None            yes\n",
      "3   A13  Feature  Categorical        None        None  None             no\n",
      "4   A12  Feature  Categorical        None        None  None             no\n",
      "5   A11  Feature   Continuous        None        None  None             no\n",
      "6   A10  Feature  Categorical        None        None  None             no\n",
      "7    A9  Feature  Categorical        None        None  None             no\n",
      "8    A8  Feature   Continuous        None        None  None             no\n",
      "9    A7  Feature  Categorical        None        None  None            yes\n",
      "10   A6  Feature  Categorical        None        None  None            yes\n",
      "11   A5  Feature  Categorical        None        None  None            yes\n",
      "12   A4  Feature  Categorical        None        None  None            yes\n",
      "13   A3  Feature   Continuous        None        None  None             no\n",
      "14   A2  Feature   Continuous        None        None  None            yes\n",
      "15   A1  Feature  Categorical        None        None  None            yes\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "credit_approval = fetch_ucirepo(id=27) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = credit_approval.data.features \n",
    "y = credit_approval.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(credit_approval.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(credit_approval.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392b600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A15    A14 A13 A12  A11 A10 A9    A8 A7 A6 A5 A4     A3     A2 A1 A16\n",
      "0    0  202.0   g   f    1   t  t  1.25  v  w  g  u  0.000  30.83  b   +\n",
      "1  560   43.0   g   f    6   t  t  3.04  h  q  g  u  4.460  58.67  a   +\n",
      "2  824  280.0   g   f    0   f  t  1.50  h  q  g  u  0.500  24.50  a   +\n",
      "3    3  100.0   g   t    5   t  t  3.75  v  w  g  u  1.540  27.83  b   +\n",
      "4    0  120.0   s   f    0   f  t  1.71  v  w  g  u  5.625  20.17  b   +\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([X, y], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35252bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame: ['A15', 'A14', 'A13', 'A12', 'A11', 'A10', 'A9', 'A8', 'A7', 'A6', 'A5', 'A4', 'A3', 'A2', 'A1', 'A16']\n"
     ]
    }
   ],
   "source": [
    "# Verificar o nome atual da coluna target\n",
    "print(\"Colunas do DataFrame:\", df.columns.tolist())\n",
    "\n",
    "# Se o target estiver com nome genérico como 'Class' ou 'Target', podemos renomear\n",
    "df = df.rename(columns={df.columns[-1]: 'Credit_Approval'})  # Assumindo que o target é a última coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db4c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir '?' por NaN\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Codificar variáveis categóricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Credit_Approval'] = le.fit_transform(df['Credit_Approval'])\n",
    "\n",
    "# One-hot encoding para outras variáveis categóricas\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2c1fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informações do DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 38 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   A15              690 non-null    int64  \n",
      " 1   A14              677 non-null    float64\n",
      " 2   A11              690 non-null    int64  \n",
      " 3   A8               690 non-null    float64\n",
      " 4   A3               690 non-null    float64\n",
      " 5   A2               678 non-null    float64\n",
      " 6   Credit_Approval  690 non-null    int64  \n",
      " 7   A13_p            690 non-null    bool   \n",
      " 8   A13_s            690 non-null    bool   \n",
      " 9   A12_t            690 non-null    bool   \n",
      " 10  A10_t            690 non-null    bool   \n",
      " 11  A9_t             690 non-null    bool   \n",
      " 12  A7_dd            690 non-null    bool   \n",
      " 13  A7_ff            690 non-null    bool   \n",
      " 14  A7_h             690 non-null    bool   \n",
      " 15  A7_j             690 non-null    bool   \n",
      " 16  A7_n             690 non-null    bool   \n",
      " 17  A7_o             690 non-null    bool   \n",
      " 18  A7_v             690 non-null    bool   \n",
      " 19  A7_z             690 non-null    bool   \n",
      " 20  A6_c             690 non-null    bool   \n",
      " 21  A6_cc            690 non-null    bool   \n",
      " 22  A6_d             690 non-null    bool   \n",
      " 23  A6_e             690 non-null    bool   \n",
      " 24  A6_ff            690 non-null    bool   \n",
      " 25  A6_i             690 non-null    bool   \n",
      " 26  A6_j             690 non-null    bool   \n",
      " 27  A6_k             690 non-null    bool   \n",
      " 28  A6_m             690 non-null    bool   \n",
      " 29  A6_q             690 non-null    bool   \n",
      " 30  A6_r             690 non-null    bool   \n",
      " 31  A6_w             690 non-null    bool   \n",
      " 32  A6_x             690 non-null    bool   \n",
      " 33  A5_gg            690 non-null    bool   \n",
      " 34  A5_p             690 non-null    bool   \n",
      " 35  A4_u             690 non-null    bool   \n",
      " 36  A4_y             690 non-null    bool   \n",
      " 37  A1_b             690 non-null    bool   \n",
      "dtypes: bool(31), float64(4), int64(3)\n",
      "memory usage: 58.8 KB\n",
      "None\n",
      "\n",
      "Estatísticas descritivas:\n",
      "                  A15          A14        A11          A8          A3  \\\n",
      "count      690.000000   677.000000  690.00000  690.000000  690.000000   \n",
      "unique            NaN          NaN        NaN         NaN         NaN   \n",
      "top               NaN          NaN        NaN         NaN         NaN   \n",
      "freq              NaN          NaN        NaN         NaN         NaN   \n",
      "mean      1017.385507   184.014771    2.40000    2.223406    4.758725   \n",
      "std       5210.102598   173.806768    4.86294    3.346513    4.978163   \n",
      "min          0.000000     0.000000    0.00000    0.000000    0.000000   \n",
      "25%          0.000000    75.000000    0.00000    0.165000    1.000000   \n",
      "50%          5.000000   160.000000    0.00000    1.000000    2.750000   \n",
      "75%        395.500000   276.000000    3.00000    2.625000    7.207500   \n",
      "max     100000.000000  2000.000000   67.00000   28.500000   28.000000   \n",
      "\n",
      "                A2  Credit_Approval  A13_p  A13_s  A12_t  ...   A6_m   A6_q  \\\n",
      "count   678.000000       690.000000    690    690    690  ...    690    690   \n",
      "unique         NaN              NaN      2      2      2  ...      2      2   \n",
      "top            NaN              NaN  False  False  False  ...  False  False   \n",
      "freq           NaN              NaN    682    633    374  ...    652    612   \n",
      "mean     31.568171         0.555072    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "std      11.957862         0.497318    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "min      13.750000         0.000000    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "25%      22.602500         0.000000    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "50%      28.460000         1.000000    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "75%      38.230000         1.000000    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "max      80.250000         1.000000    NaN    NaN    NaN  ...    NaN    NaN   \n",
      "\n",
      "         A6_r   A6_w   A6_x  A5_gg   A5_p  A4_u   A4_y  A1_b  \n",
      "count     690    690    690    690    690   690    690   690  \n",
      "unique      2      2      2      2      2     2      2     2  \n",
      "top     False  False  False  False  False  True  False  True  \n",
      "freq      687    626    652    688    527   519    527   468  \n",
      "mean      NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "std       NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "min       NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "25%       NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "50%       NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "75%       NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "max       NaN    NaN    NaN    NaN    NaN   NaN    NaN   NaN  \n",
      "\n",
      "[11 rows x 38 columns]\n",
      "\n",
      "Valores ausentes por coluna:\n",
      "A15                 0\n",
      "A14                13\n",
      "A11                 0\n",
      "A8                  0\n",
      "A3                  0\n",
      "A2                 12\n",
      "Credit_Approval     0\n",
      "A13_p               0\n",
      "A13_s               0\n",
      "A12_t               0\n",
      "A10_t               0\n",
      "A9_t                0\n",
      "A7_dd               0\n",
      "A7_ff               0\n",
      "A7_h                0\n",
      "A7_j                0\n",
      "A7_n                0\n",
      "A7_o                0\n",
      "A7_v                0\n",
      "A7_z                0\n",
      "A6_c                0\n",
      "A6_cc               0\n",
      "A6_d                0\n",
      "A6_e                0\n",
      "A6_ff               0\n",
      "A6_i                0\n",
      "A6_j                0\n",
      "A6_k                0\n",
      "A6_m                0\n",
      "A6_q                0\n",
      "A6_r                0\n",
      "A6_w                0\n",
      "A6_x                0\n",
      "A5_gg               0\n",
      "A5_p                0\n",
      "A4_u                0\n",
      "A4_y                0\n",
      "A1_b                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInformações do DataFrame:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e945a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores ausentes após tratamento:\n",
      "A15                0\n",
      "A14                0\n",
      "A11                0\n",
      "A8                 0\n",
      "A3                 0\n",
      "A2                 0\n",
      "Credit_Approval    0\n",
      "A13_p              0\n",
      "A13_s              0\n",
      "A12_t              0\n",
      "A10_t              0\n",
      "A9_t               0\n",
      "A7_dd              0\n",
      "A7_ff              0\n",
      "A7_h               0\n",
      "A7_j               0\n",
      "A7_n               0\n",
      "A7_o               0\n",
      "A7_v               0\n",
      "A7_z               0\n",
      "A6_c               0\n",
      "A6_cc              0\n",
      "A6_d               0\n",
      "A6_e               0\n",
      "A6_ff              0\n",
      "A6_i               0\n",
      "A6_j               0\n",
      "A6_k               0\n",
      "A6_m               0\n",
      "A6_q               0\n",
      "A6_r               0\n",
      "A6_w               0\n",
      "A6_x               0\n",
      "A5_gg              0\n",
      "A5_p               0\n",
      "A4_u               0\n",
      "A4_y               0\n",
      "A1_b               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Para colunas numéricas, preencher com mediana\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "# Para colunas categóricas, preencher com moda\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Verificar novamente valores ausentes\n",
    "print(\"\\nValores ausentes após tratamento:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_target(df, mes_referencia):\n",
    "    \"\"\"\n",
    "    Cria a variável target para um mês de referência\n",
    "    \n",
    "    Parâmetros:\n",
    "    df: DataFrame com os dados\n",
    "    mes_referencia: mês de referência no formato 'YYYY-MM'\n",
    "    \n",
    "    Retorna:\n",
    "    Series com a target (1 se contratou crédito nos 3 meses seguintes, 0 caso contrário)\n",
    "    \"\"\"\n",
    "    inicio = pd.to_datetime(mes_referencia)\n",
    "    fim = inicio + pd.DateOffset(months=3)\n",
    "    \n",
    "    # Identificar clientes que contrataram no período\n",
    "    contratantes = df[(df['data'] > inicio) & \n",
    "                     (df['data'] <= fim) & \n",
    "                     (df['contratou_credito'] == 1)]['id_cliente'].unique()\n",
    "    \n",
    "    # Criar target\n",
    "    target = df[df['data'] == inicio]['id_cliente'].isin(contratantes).astype(int)\n",
    "    \n",
    "    return target\n",
    "\n",
    "# Exemplo para abril\n",
    "target_abril = criar_target(dados, '2023-04-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_features_autorregressivas(df, id_cliente, data_referencia, meses_hist=[1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Cria features autorregressivas para um cliente em uma data específica\n",
    "    \n",
    "    Parâmetros:\n",
    "    df: DataFrame com os dados\n",
    "    id_cliente: ID do cliente\n",
    "    data_referencia: data de referência\n",
    "    meses_hist: lista de meses históricos para calcular as estatísticas\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame com as features para o cliente na data de referência\n",
    "    \"\"\"\n",
    "    data_ref = pd.to_datetime(data_referencia)\n",
    "    features = {}\n",
    "    \n",
    "    for meses in meses_hist:\n",
    "        # Filtrar dados históricos\n",
    "        historico = df[(df['id_cliente'] == id_cliente) & \n",
    "                       (df['data'] <= data_ref) & \n",
    "                       (df['data'] > data_ref - pd.DateOffset(months=meses))]\n",
    "        \n",
    "        # Calcular estatísticas\n",
    "        if not historico.empty:\n",
    "            features[f'limite_utilizado_media_{meses}m'] = historico['limite_utilizado'].mean()\n",
    "            features[f'limite_utilizado_min_{meses}m'] = historico['limite_utilizado'].min()\n",
    "            features[f'limite_utilizado_max_{meses}m'] = historico['limite_utilizado'].max()\n",
    "            features[f'qtd_transacoes_{meses}m'] = historico.shape[0]\n",
    "        else:\n",
    "            # Preencher com zeros se não houver histórico\n",
    "            features[f'limite_utilizado_media_{meses}m'] = 0\n",
    "            features[f'limite_utilizado_min_{meses}m'] = 0\n",
    "            features[f'limite_utilizado_max_{meses}m'] = 0\n",
    "            features[f'qtd_transacoes_{meses}m'] = 0\n",
    "    \n",
    "    return pd.DataFrame(features, index=[0])\n",
    "\n",
    "# Exemplo de aplicação para todos os clientes em um mês específico\n",
    "def criar_dataset_mes(df, mes_referencia):\n",
    "    data_ref = pd.to_datetime(mes_referencia)\n",
    "    clientes_mes = df[df['data'] == data_ref]['id_cliente'].unique()\n",
    "    \n",
    "    features_list = []\n",
    "    for cliente in clientes_mes:\n",
    "        features = criar_features_autorregressivas(df, cliente, data_ref)\n",
    "        features['id_cliente'] = cliente\n",
    "        features['data'] = data_ref\n",
    "        features_list.append(features)\n",
    "    \n",
    "    return pd.concat(features_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar datasets para cada mês\n",
    "meses_treino = ['2023-04-01', '2023-05-01', '2023-06-01']\n",
    "meses_teste = ['2023-07-01', '2023-08-01']\n",
    "\n",
    "# Criar features e targets para treino\n",
    "X_treino_list = []\n",
    "y_treino_list = []\n",
    "\n",
    "for mes in meses_treino:\n",
    "    # Criar features\n",
    "    features_mes = criar_dataset_mes(dados, mes)\n",
    "    X_treino_list.append(features_mes)\n",
    "    \n",
    "    # Criar target\n",
    "    target_mes = criar_target(dados, mes)\n",
    "    y_treino_list.append(target_mes)\n",
    "\n",
    "X_treino = pd.concat(X_treino_list)\n",
    "y_treino = pd.concat(y_treino_list)\n",
    "\n",
    "# Criar features e targets para teste\n",
    "X_teste_list = []\n",
    "y_teste_list = []\n",
    "\n",
    "for mes in meses_teste:\n",
    "    features_mes = criar_dataset_mes(dados, mes)\n",
    "    X_teste_list.append(features_mes)\n",
    "    \n",
    "    target_mes = criar_target(dados, mes)\n",
    "    y_teste_list.append(target_mes)\n",
    "\n",
    "X_teste = pd.concat(X_teste_list)\n",
    "y_teste = pd.concat(y_teste_list)\n",
    "\n",
    "# Remover colunas não utilizadas no modelo\n",
    "cols_modelo = [col for col in X_treino.columns if col not in ['id_cliente', 'data']]\n",
    "X_treino = X_treino[cols_modelo]\n",
    "X_teste = X_teste[cols_modelo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107cdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar X e y para balanceamento\n",
    "df_treino = pd.concat([X_treino, y_treino], axis=1)\n",
    "\n",
    "# Separar classes\n",
    "classe_maioria = df_treino[df_treino['target'] == 0]\n",
    "classe_minoria = df_treino[df_treino['target'] == 1]\n",
    "\n",
    "# Undersampling da classe majoritária\n",
    "classe_maioria_downsampled = resample(classe_maioria,\n",
    "                                     replace=False,\n",
    "                                     n_samples=len(classe_minoria),\n",
    "                                     random_state=42)\n",
    "\n",
    "# Combinar as classes balanceadas\n",
    "df_treino_balanced = pd.concat([classe_maioria_downsampled, classe_minoria])\n",
    "\n",
    "# Separar novamente X e y\n",
    "X_treino_balanced = df_treino_balanced.drop('target', axis=1)\n",
    "y_treino_balanced = df_treino_balanced['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd26280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar pipeline com normalização e modelo\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(class_weight='balanced', \n",
    "                                random_state=42,\n",
    "                                max_iter=1000))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_treino_balanced, y_treino_balanced)\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "y_pred = pipeline.predict(X_teste)\n",
    "y_pred_proba = pipeline.predict_proba(X_teste)[:, 1]\n",
    "\n",
    "# Avaliação\n",
    "print(classification_report(y_teste, y_pred))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_teste, y_pred_proba)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c70ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair coeficientes do modelo\n",
    "coeficientes = pipeline.named_steps['model'].coef_[0]\n",
    "features_importance = pd.DataFrame({\n",
    "    'Feature': cols_modelo,\n",
    "    'Importance': coeficientes\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(features_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353056ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_propensao(df, mes_referencia, modelo):\n",
    "    \"\"\"\n",
    "    Prever propensão para contratação de crédito para um mês específico\n",
    "    \n",
    "    Parâmetros:\n",
    "    df: DataFrame com os dados\n",
    "    mes_referencia: mês de referência no formato 'YYYY-MM'\n",
    "    modelo: modelo treinado\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame com IDs dos clientes e suas probabilidades de propensão\n",
    "    \"\"\"\n",
    "    # Criar features\n",
    "    features = criar_dataset_mes(df, mes_referencia)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    X = features[cols_modelo]\n",
    "    features['probabilidade'] = modelo.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return features[['id_cliente', 'data', 'probabilidade']].sort_values('probabilidade', ascending=False)\n",
    "\n",
    "# Exemplo de uso\n",
    "propensao_setembro = prever_propensao(dados, '2023-09-01', pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f86da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
